{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with spatial transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "        # Spatial transformer localization-network\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 3 * 3, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "        )\n",
    "\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "    # Spatial transformer network forward function\n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)\n",
    "        xs = xs.view(-1, 10 * 3 * 3)\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # transform the input\n",
    "        x = self.stn(x)\n",
    "\n",
    "        # Perform the usual forward pass\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, train_loader):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    model.train()\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 500 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "#\n",
    "# A simple test procedure to measure STN the performances on MNIST.\n",
    "#\n",
    "\n",
    "def test(test_loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            # sum up batch loss\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "              .format(test_loss, correct, len(test_loader.dataset),\n",
    "                      100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "######################################################################\n",
    "# Visualizing the STN results\n",
    "# ---------------------------\n",
    "#\n",
    "# Now, we will inspect the results of our learned visual attention\n",
    "# mechanism.\n",
    "#\n",
    "# We define a small helper function in order to visualize the\n",
    "# transformations while training.\n",
    "\n",
    "\n",
    "def convert_image_np(inp):\n",
    "    \"\"\"Convert a Tensor to numpy image.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    return inp\n",
    "\n",
    "# We want to visualize the output of the spatial transformers layer\n",
    "# after the training, we visualize a batch of input images and\n",
    "# the corresponding transformed batch using STN.\n",
    "\n",
    "\n",
    "def visualize_stn(test_loader):\n",
    "    with torch.no_grad():\n",
    "        # Get a batch of training data\n",
    "        data = next(iter(test_loader))[0].to(device)\n",
    "\n",
    "        input_tensor = data.cpu()\n",
    "        transformed_input_tensor = model.stn(data).cpu()\n",
    "\n",
    "        in_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(input_tensor))\n",
    "\n",
    "        out_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(transformed_input_tensor))\n",
    "\n",
    "        # scipy.misc.imsave('in_grid.png', in_grid)\n",
    "        # scipy.misc.imsave('out_grid.png', out_grid)\n",
    "        torchvision.utils.save_image(input_tensor, \"in_grid_img.png\", nrow=8, padding=2, normalize=False, range=None, scale_each=False,\n",
    "                                     pad_value=0)\n",
    "\n",
    "        torchvision.utils.save_image(transformed_input_tensor, \"out_grid_img.png\", nrow=8, padding=2, normalize=False, range=None,\n",
    "                                     scale_each=False,\n",
    "                                     pad_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing MNIST and distort it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(root='./datasets', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.RandomAffine(45),\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])), batch_size=64, shuffle=True, num_workers=4)\n",
    "# Test dataset\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(root='./datasets', train=False, transform=transforms.Compose([\n",
    "        transforms.RandomAffine(45),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])), batch_size=64, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the GTSRB and distort it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.8863,  0.8078,  0.8078,  0.5020,  0.4667,\n",
      "           0.3882,  0.4157,  0.4157,  0.3882,  0.2784,  0.2510,  0.2863,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.9216,  0.9529,  0.9412,  0.9412,  0.5098,  0.5098,\n",
      "           0.3608,  0.3373,  0.4824,  0.3216,  0.3059,  0.2745,  0.2824,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.6706,\n",
      "           0.7961,  0.8941,  0.9725,  0.9725,  0.7608,  0.6667,  0.3725,\n",
      "           0.4745,  0.4745,  0.3333,  0.2980,  0.2745,  0.2863,  0.2784,\n",
      "           0.2706,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.7490,  0.6706,\n",
      "           0.6471,  0.5922,  0.7882,  0.8000,  0.3961,  0.3961,  0.4000,\n",
      "           0.3765,  0.3529,  0.3373,  0.3216,  0.2941,  0.3020,  0.2863,\n",
      "           0.2902,  0.2824,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.6235,  0.8667,  0.8667,\n",
      "           0.7686,  0.5922,  0.8588,  0.4275,  0.4078,  0.3882,  0.5098,\n",
      "           0.4275,  0.3490,  0.3373,  0.3176,  0.3216,  0.3098,  0.2980,\n",
      "           0.3216,  0.3216,  0.3059,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.8157,  0.6039,  0.8667,  0.8157,\n",
      "           0.9098,  0.8824,  0.4157,  0.4275,  0.3765,  0.6157,  0.5098,\n",
      "           0.4667,  0.4000,  0.4118,  0.3373,  0.3216,  0.3059,  0.3333,\n",
      "           0.3373,  0.3529,  0.3176,  0.3176,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.9686,  0.9843,  0.9569,  0.7412,  0.6039,  0.9294,\n",
      "           0.9098,  0.4667,  0.3216,  0.3490,  0.4980,  0.4157,  0.4510,\n",
      "           0.3412,  0.4000,  0.4549,  0.4392,  0.3529,  0.3216,  0.3725,\n",
      "           0.3725,  0.3725,  0.3490,  0.3255,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.7059,  0.9843,  0.9765,  0.9333,  0.7412,  0.7216,  0.5490,\n",
      "           0.5216,  0.3294,  0.3294,  0.5804,  0.3686,  0.4157,  0.3529,\n",
      "           0.5529,  0.4863,  0.4157,  0.4392,  0.4118,  0.5216,  0.3686,\n",
      "           0.3765,  0.3569,  0.3569,  0.3412,  0.3333,  0.0000,  0.0000],\n",
      "         [ 0.8941,  0.9922,  1.0000,  0.9725,  0.8745,  0.5922,  0.5490,\n",
      "           0.3373,  0.5529,  0.5529,  0.3686,  0.3686,  0.4784,  0.7255,\n",
      "           0.5529,  0.6157,  0.5922,  0.5255,  0.3686,  0.5216,  0.3843,\n",
      "           0.4039,  0.3686,  0.3529,  0.3294,  0.3294,  0.3529,  0.0000],\n",
      "         [ 0.3804,  0.9373,  0.9804,  0.9804,  0.6902,  0.6392,  0.3333,\n",
      "           0.5608,  0.5608,  0.3804,  0.6588,  0.5725,  0.8863,  0.8863,\n",
      "           0.8000,  0.4196,  0.5922,  0.5725,  0.8588,  0.3333,  0.4980,\n",
      "           0.4039,  0.4039,  0.3412,  0.3412,  0.3333,  0.3451,  0.3412],\n",
      "         [ 0.4471,  0.4863,  0.9804,  0.7373,  0.3451,  0.3451,  0.5333,\n",
      "           0.4980,  0.3569,  0.5059,  0.5059,  0.9608,  0.9294,  0.8588,\n",
      "           0.4196,  0.7882,  0.6824,  0.5098,  0.8588,  0.8549,  0.3059,\n",
      "           0.4941,  0.3922,  0.3373,  0.3373,  0.3412,  0.3451,  0.3216],\n",
      "         [ 0.3843,  0.5804,  0.7059,  0.3725,  0.3569,  0.5098,  0.5176,\n",
      "           0.5176,  0.3137,  0.7843,  0.8627,  0.9333,  0.9333,  0.7451,\n",
      "           0.6627,  0.7882,  0.8314,  0.7255,  0.4706,  0.8588,  0.3059,\n",
      "           0.3333,  0.3725,  0.3804,  0.3373,  0.3412,  0.3686,  0.3490],\n",
      "         [ 0.4902,  0.3490,  0.3843,  0.4667,  0.4667,  0.4000,  0.4549,\n",
      "           0.3882,  0.5765,  0.5765,  0.8784,  0.6314,  0.8392,  0.5294,\n",
      "           0.5647,  0.4941,  0.8745,  0.7255,  0.7647,  0.4549,  0.7922,\n",
      "           0.3647,  0.3647,  0.4471,  0.3137,  0.3412,  0.3608,  0.3333],\n",
      "         [ 0.4902,  0.3569,  0.4000,  0.4353,  0.3882,  0.4392,  0.4392,\n",
      "           0.4353,  0.3529,  0.8235,  0.4275,  0.4275,  0.5020,  0.4784,\n",
      "           0.5804,  0.6118,  0.4706,  0.8196,  0.6157,  0.4549,  0.6549,\n",
      "           0.5294,  0.3961,  0.3608,  0.3608,  0.3137,  0.3608,  0.3333],\n",
      "         [ 0.5137,  0.5294,  0.4000,  0.6157,  0.3647,  0.3843,  0.4745,\n",
      "           0.3490,  0.3490,  0.8000,  0.5882,  0.4706,  0.8706,  0.4902,\n",
      "           0.5294,  0.6314,  0.4314,  0.4235,  0.4745,  0.5255,  0.8902,\n",
      "           0.8902,  0.3412,  0.4078,  0.3098,  0.3216,  0.3098,  0.3373],\n",
      "         [ 0.4824,  0.7098,  0.6745,  0.6157,  0.3686,  0.3686,  0.5333,\n",
      "           0.3922,  0.5412,  0.7176,  0.7804,  0.8039,  0.6745,  0.4510,\n",
      "           0.6118,  0.8392,  0.6588,  0.4235,  0.4235,  0.8392,  0.8706,\n",
      "           0.6157,  0.4314,  0.4314,  0.3255,  0.2863,  0.3098,  0.3176],\n",
      "         [ 0.6980,  0.7098,  0.7137,  0.5922,  0.6118,  0.3765,  0.4706,\n",
      "           0.4706,  0.3725,  0.7176,  0.7686,  0.8549,  0.8824,  0.5412,\n",
      "           0.8000,  0.7098,  0.5608,  0.6784,  0.7569,  0.9059,  0.9059,\n",
      "           0.7333,  0.6314,  0.5255,  0.3373,  0.3373,  0.2941,  0.2706],\n",
      "         [ 0.7176,  0.7176,  0.6941,  0.5922,  0.4431,  0.5961,  0.3961,\n",
      "           0.3882,  0.3922,  0.4275,  0.8824,  0.8549,  0.7451,  0.6431,\n",
      "           0.4392,  0.4824,  0.6510,  0.6510,  0.9373,  0.9608,  0.9059,\n",
      "           0.5333,  0.5333,  0.4941,  0.4745,  0.3725,  0.4118,  0.3294],\n",
      "         [ 0.7176,  0.6863,  0.4431,  0.4784,  0.4353,  0.4353,  0.5922,\n",
      "           0.4902,  0.3922,  0.4353,  0.4471,  0.8471,  0.8745,  0.6431,\n",
      "           0.5333,  0.6118,  0.6078,  0.9451,  0.8902,  0.8902,  0.3882,\n",
      "           0.4431,  0.4824,  0.5686,  0.5686,  0.4431,  0.3922,  0.3647],\n",
      "         [ 0.6902,  0.4706,  0.4431,  0.5922,  0.3098,  0.3490,  0.5922,\n",
      "           0.5490,  0.5882,  0.4549,  0.4471,  0.8392,  0.6471,  0.8196,\n",
      "           0.5216,  0.8745,  0.8745,  0.8745,  0.8902,  0.3412,  0.5216,\n",
      "           0.5216,  0.5020,  0.4627,  0.4510,  0.4118,  0.5059,  0.3882],\n",
      "         [ 0.0000,  0.5490,  0.8353,  0.7373,  0.7373,  0.3333,  0.4078,\n",
      "           0.5490,  0.5216,  0.4392,  0.3569,  0.3294,  0.6471,  0.4431,\n",
      "           0.4824,  0.6784,  0.6510,  0.3725,  0.3725,  0.5882,  0.4392,\n",
      "           0.4706,  0.4275,  0.4510,  0.4118,  0.4902,  0.5765,  0.5333],\n",
      "         [ 0.0000,  0.0000,  0.5608,  0.5490,  0.6392,  0.4039,  0.4039,\n",
      "           0.4902,  0.4157,  0.4392,  0.5020,  0.5176,  0.3647,  0.4627,\n",
      "           0.4824,  0.3922,  0.5137,  0.4392,  0.4431,  0.5647,  0.5647,\n",
      "           0.4902,  0.4275,  0.4667,  0.4196,  0.3529,  0.5608,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.5333,  0.5333,  0.5098,  0.4980,  0.4824,\n",
      "           0.3882,  0.3882,  0.5451,  0.6157,  0.5176,  0.4588,  0.4157,\n",
      "           0.3843,  0.4980,  0.5137,  0.4667,  0.5294,  0.4980,  0.5529,\n",
      "           0.4902,  0.5569,  0.4157,  0.4196,  0.3725,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.4902,  0.5176,  0.5176,  0.4118,\n",
      "           0.5569,  0.5490,  0.6784,  0.6784,  0.5843,  0.4235,  0.4157,\n",
      "           0.3765,  0.3922,  0.4196,  0.4510,  0.5490,  0.5373,  0.3608,\n",
      "           0.4902,  0.5569,  0.5725,  0.4235,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.4118,  0.4118,  0.5490,\n",
      "           0.5490,  0.6824,  0.6902,  0.6784,  0.5843,  0.5843,  0.3333,\n",
      "           0.3686,  0.3922,  0.4235,  0.5569,  0.5490,  0.4275,  0.3137,\n",
      "           0.3216,  0.4235,  0.5725,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.5294,  0.6902,\n",
      "           0.6941,  0.7059,  0.6902,  0.6549,  0.4157,  0.5843,  0.5843,\n",
      "           0.4314,  0.4471,  0.5451,  0.5451,  0.4196,  0.3490,  0.3137,\n",
      "           0.2863,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.6824,\n",
      "           0.7216,  0.7333,  0.6902,  0.4902,  0.2353,  0.3725,  0.6039,\n",
      "           0.6039,  0.5451,  0.4353,  0.4196,  0.3765,  0.3765,  0.3725,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.7216,\n",
      "           0.7059,  0.7176,  0.7451,  0.5176,  0.2706,  0.2902,  0.3922,\n",
      "           0.5569,  0.4510,  0.4510,  0.3451,  0.3216,  0.3451,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]), 0)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import csv\n",
    "from PIL import Image\n",
    "\n",
    "path_train = './data/train/GTSRB/Final_Training/Images'\n",
    "path_test = \"./data/test/GTSRB/Final_Test/Images\"\n",
    "\n",
    "\n",
    "class TrafficSignals(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset wrapping images and target labels for Kaggle - Planet Amazon from Space competition.\n",
    "\n",
    "    Arguments:\n",
    "        A CSV file path\n",
    "        Path to image folder\n",
    "        Extension of images\n",
    "        PIL transforms\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path_train, path_test, train=False, transform=None):\n",
    "\n",
    "        self.path_train = path_train\n",
    "        self.path_test = path_test\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "        if train:\n",
    "            [self.X_train, self.y_train] = self.readTrafficSigns(path_train, train=True)\n",
    "\n",
    "        else:\n",
    "            [self.X_train, self.y_train] = self.readTrafficSigns(path_test, train=False)\n",
    "\n",
    "        # print(self.y_train)\n",
    "        # print(self.X_train)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.X_train[index]).resize((28,28), resample=0)\n",
    "        if self.transform is not None:\n",
    "             img = self.transform(img)\n",
    "        label = int(self.y_train[index])\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_train)\n",
    "\n",
    "    def readTrafficSigns(self, rootpath, train=False):\n",
    "        '''Reads traffic sign data for German Traffic Sign Recognition Benchmark.\n",
    "\n",
    "        Arguments: path to the traffic sign data, for example './GTSRB/Training'\n",
    "        Returns:   list of images, list of corresponding labels'''\n",
    "        images = []  # images\n",
    "        labels = []  # corresponding labels\n",
    "\n",
    "        if train:\n",
    "\n",
    "        # loop over all 42 classes\n",
    "            for c in range(0, 43):\n",
    "                # prefix = rootpath + '/'  # subdirectory for class\n",
    "                prefix = rootpath + '/' + format(c, '05d') + '/' # subdirectory for class\n",
    "                gtFile = open(prefix + 'GT-'+ format(c, '05d') + '.csv') # annotations file\n",
    "                gtReader = csv.reader(gtFile, delimiter=';')  # csv parser for annotations file\n",
    "                next(gtReader)  # skip header\n",
    "                # loop over all images in current annotations file\n",
    "                for row in gtReader:\n",
    "                    images.append(prefix + row[0])  # the 1th column is the filename\n",
    "                    # images.append(plt.imread(prefix + row[0]))  # the 1th column is the filename\n",
    "                    labels.append(row[7])  # the 8th column is the label\n",
    "                gtFile.close()\n",
    "\n",
    "        else:\n",
    "            prefix = rootpath + '/' # subdirectory for class\n",
    "            gtFile = open(prefix + 'GT-final_test.csv') # annotations file\n",
    "            gtReader = csv.reader(gtFile, delimiter=';')  # csv parser for annotations file\n",
    "            next(gtReader)  # skip header\n",
    "            # loop over all images in current annotations file\n",
    "            for row in gtReader:\n",
    "                images.append(prefix + row[0])  # the 1th column is the filename\n",
    "                # images.append(plt.imread(prefix + row[0]))  # the 1th column is the filename\n",
    "                labels.append(row[7])  # the 8th column is the label\n",
    "            gtFile.close()\n",
    "        return images, labels\n",
    "\n",
    "    \n",
    "#train dataset loader\n",
    "dset_train = TrafficSignals(path_train, path_test, train=True, transform=transforms.Compose([\n",
    "                       transforms.Grayscale(),\n",
    "                       transforms.RandomAffine(45),\n",
    "                       transforms.ToTensor(),\n",
    "                   ]))\n",
    "print(dset_train.__getitem__(1))\n",
    "dset_train = torch.utils.data.DataLoader(dset_train,\n",
    "                          batch_size=64,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4\n",
    "                         # pin_memory=True # CUDA only\n",
    "                         )\n",
    "\n",
    "#test dataset loader\n",
    "dset_test = TrafficSignals(path_train, path_test, transform=transforms.Compose([\n",
    "                       transforms.Grayscale(),\n",
    "                    transforms.RandomAffine(45),\n",
    "                       transforms.ToTensor(),\n",
    "                   ]))\n",
    "dset_test = torch.utils.data.DataLoader(dset_test,\n",
    "                          batch_size=64,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4\n",
    "                         # pin_memory=True # CUDA only\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test for the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.190533\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.383691\n",
      "\n",
      "Test set: Average loss: 0.1011, Accuracy: 9685/10000 (97%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.041331\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.117734\n",
      "\n",
      "Test set: Average loss: 0.0738, Accuracy: 9773/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.161919\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.241965\n",
      "\n",
      "Test set: Average loss: 0.0638, Accuracy: 9808/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.154912\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.119330\n",
      "\n",
      "Test set: Average loss: 0.0726, Accuracy: 9768/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.187385\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.208705\n",
      "\n",
      "Test set: Average loss: 0.0677, Accuracy: 9786/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.189368\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.144360\n",
      "\n",
      "Test set: Average loss: 0.0620, Accuracy: 9805/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.242441\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.110944\n",
      "\n",
      "Test set: Average loss: 0.0682, Accuracy: 9792/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.139667\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.229938\n",
      "\n",
      "Test set: Average loss: 0.0685, Accuracy: 9792/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.438696\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.365259\n",
      "\n",
      "Test set: Average loss: 0.0603, Accuracy: 9821/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.034123\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.217536\n",
      "\n",
      "Test set: Average loss: 0.0676, Accuracy: 9802/10000 (98%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.185845\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.289419\n",
      "\n",
      "Test set: Average loss: 0.0583, Accuracy: 9822/10000 (98%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.170110\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.151734\n",
      "\n",
      "Test set: Average loss: 0.0657, Accuracy: 9778/10000 (98%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.068944\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.304741\n",
      "\n",
      "Test set: Average loss: 0.0582, Accuracy: 9826/10000 (98%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.401864\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.212033\n",
      "\n",
      "Test set: Average loss: 0.0619, Accuracy: 9812/10000 (98%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.173249\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.158460\n",
      "\n",
      "Test set: Average loss: 0.0618, Accuracy: 9817/10000 (98%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.173189\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.084880\n",
      "\n",
      "Test set: Average loss: 0.0700, Accuracy: 9780/10000 (98%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.126015\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 0.253914\n",
      "\n",
      "Test set: Average loss: 0.0703, Accuracy: 9779/10000 (98%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.213377\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 0.246270\n",
      "\n",
      "Test set: Average loss: 0.0641, Accuracy: 9818/10000 (98%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.071081\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 0.155906\n",
      "\n",
      "Test set: Average loss: 0.0767, Accuracy: 9763/10000 (98%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.145775\n",
      "Train Epoch: 20 [32000/60000 (53%)]\tLoss: 0.162177\n",
      "\n",
      "Test set: Average loss: 0.0621, Accuracy: 9811/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 20 + 1):\n",
    "    train(epoch, train_loader)\n",
    "    test(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test for GTSRB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/39209 (0%)]\tLoss: 3.754161\n",
      "Train Epoch: 1 [32000/39209 (82%)]\tLoss: 3.661552\n",
      "\n",
      "Test set: Average loss: 3.5177, Accuracy: 720/12630 (6%)\n",
      "\n",
      "Train Epoch: 2 [0/39209 (0%)]\tLoss: 3.596776\n",
      "Train Epoch: 2 [32000/39209 (82%)]\tLoss: 3.563682\n",
      "\n",
      "Test set: Average loss: 3.4819, Accuracy: 720/12630 (6%)\n",
      "\n",
      "Train Epoch: 3 [0/39209 (0%)]\tLoss: 3.594419\n",
      "Train Epoch: 3 [32000/39209 (82%)]\tLoss: 3.633026\n",
      "\n",
      "Test set: Average loss: 3.4692, Accuracy: 720/12630 (6%)\n",
      "\n",
      "Train Epoch: 4 [0/39209 (0%)]\tLoss: 3.612273\n",
      "Train Epoch: 4 [32000/39209 (82%)]\tLoss: 3.602080\n",
      "\n",
      "Test set: Average loss: 3.4597, Accuracy: 775/12630 (6%)\n",
      "\n",
      "Train Epoch: 5 [0/39209 (0%)]\tLoss: 3.435731\n",
      "Train Epoch: 5 [32000/39209 (82%)]\tLoss: 3.431840\n",
      "\n",
      "Test set: Average loss: 3.4308, Accuracy: 1067/12630 (8%)\n",
      "\n",
      "Train Epoch: 6 [0/39209 (0%)]\tLoss: 3.606174\n",
      "Train Epoch: 6 [32000/39209 (82%)]\tLoss: 3.430386\n",
      "\n",
      "Test set: Average loss: 3.4001, Accuracy: 1372/12630 (11%)\n",
      "\n",
      "Train Epoch: 7 [0/39209 (0%)]\tLoss: 3.490295\n",
      "Train Epoch: 7 [32000/39209 (82%)]\tLoss: 3.479346\n",
      "\n",
      "Test set: Average loss: 3.3899, Accuracy: 1477/12630 (12%)\n",
      "\n",
      "Train Epoch: 8 [0/39209 (0%)]\tLoss: 3.572165\n",
      "Train Epoch: 8 [32000/39209 (82%)]\tLoss: 3.527254\n",
      "\n",
      "Test set: Average loss: 3.3521, Accuracy: 1617/12630 (13%)\n",
      "\n",
      "Train Epoch: 9 [0/39209 (0%)]\tLoss: 3.316792\n",
      "Train Epoch: 9 [32000/39209 (82%)]\tLoss: 3.317023\n",
      "\n",
      "Test set: Average loss: 3.2299, Accuracy: 2017/12630 (16%)\n",
      "\n",
      "Train Epoch: 10 [0/39209 (0%)]\tLoss: 3.165937\n",
      "Train Epoch: 10 [32000/39209 (82%)]\tLoss: 3.363375\n",
      "\n",
      "Test set: Average loss: 2.9681, Accuracy: 2782/12630 (22%)\n",
      "\n",
      "Train Epoch: 11 [0/39209 (0%)]\tLoss: 3.053837\n",
      "Train Epoch: 11 [32000/39209 (82%)]\tLoss: 2.722519\n",
      "\n",
      "Test set: Average loss: 2.6983, Accuracy: 3510/12630 (28%)\n",
      "\n",
      "Train Epoch: 12 [0/39209 (0%)]\tLoss: 3.007939\n",
      "Train Epoch: 12 [32000/39209 (82%)]\tLoss: 2.468008\n",
      "\n",
      "Test set: Average loss: 2.4627, Accuracy: 4291/12630 (34%)\n",
      "\n",
      "Train Epoch: 13 [0/39209 (0%)]\tLoss: 2.664521\n",
      "Train Epoch: 13 [32000/39209 (82%)]\tLoss: 2.507504\n",
      "\n",
      "Test set: Average loss: 2.3014, Accuracy: 5005/12630 (40%)\n",
      "\n",
      "Train Epoch: 14 [0/39209 (0%)]\tLoss: 2.391501\n",
      "Train Epoch: 14 [32000/39209 (82%)]\tLoss: 2.617065\n",
      "\n",
      "Test set: Average loss: 2.2778, Accuracy: 4824/12630 (38%)\n",
      "\n",
      "Train Epoch: 15 [0/39209 (0%)]\tLoss: 2.427964\n",
      "Train Epoch: 15 [32000/39209 (82%)]\tLoss: 2.233545\n",
      "\n",
      "Test set: Average loss: 2.1870, Accuracy: 5191/12630 (41%)\n",
      "\n",
      "Train Epoch: 16 [0/39209 (0%)]\tLoss: 2.398517\n",
      "Train Epoch: 16 [32000/39209 (82%)]\tLoss: 2.234166\n",
      "\n",
      "Test set: Average loss: 1.9405, Accuracy: 6028/12630 (48%)\n",
      "\n",
      "Train Epoch: 17 [0/39209 (0%)]\tLoss: 2.031048\n",
      "Train Epoch: 17 [32000/39209 (82%)]\tLoss: 2.130892\n",
      "\n",
      "Test set: Average loss: 1.8757, Accuracy: 6398/12630 (51%)\n",
      "\n",
      "Train Epoch: 18 [0/39209 (0%)]\tLoss: 2.117249\n",
      "Train Epoch: 18 [32000/39209 (82%)]\tLoss: 1.958005\n",
      "\n",
      "Test set: Average loss: 1.7348, Accuracy: 6957/12630 (55%)\n",
      "\n",
      "Train Epoch: 19 [0/39209 (0%)]\tLoss: 2.419769\n",
      "Train Epoch: 19 [32000/39209 (82%)]\tLoss: 1.872240\n",
      "\n",
      "Test set: Average loss: 1.9413, Accuracy: 6202/12630 (49%)\n",
      "\n",
      "Train Epoch: 20 [0/39209 (0%)]\tLoss: 1.820347\n",
      "Train Epoch: 20 [32000/39209 (82%)]\tLoss: 1.776721\n",
      "\n",
      "Test set: Average loss: 1.6406, Accuracy: 7325/12630 (58%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 20 + 1):\n",
    "    train(epoch, dset_train)\n",
    "    test(dset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model without spatial transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Perform the usual forward pass\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test for the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.326681\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.637515\n",
      "\n",
      "Test set: Average loss: 0.7005, Accuracy: 8098/10000 (81%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.154671\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.865778\n",
      "\n",
      "Test set: Average loss: 0.4183, Accuracy: 8816/10000 (88%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.724624\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.709928\n",
      "\n",
      "Test set: Average loss: 0.2993, Accuracy: 9183/10000 (92%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.518698\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.523415\n",
      "\n",
      "Test set: Average loss: 0.2556, Accuracy: 9264/10000 (93%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.396971\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.447880\n",
      "\n",
      "Test set: Average loss: 0.2205, Accuracy: 9350/10000 (94%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.550620\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.453717\n",
      "\n",
      "Test set: Average loss: 0.2054, Accuracy: 9391/10000 (94%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.569704\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.411528\n",
      "\n",
      "Test set: Average loss: 0.1816, Accuracy: 9447/10000 (94%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.327637\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.395473\n",
      "\n",
      "Test set: Average loss: 0.1741, Accuracy: 9441/10000 (94%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.632987\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.323100\n",
      "\n",
      "Test set: Average loss: 0.1614, Accuracy: 9519/10000 (95%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.426569\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.342853\n",
      "\n",
      "Test set: Average loss: 0.1578, Accuracy: 9511/10000 (95%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.465268\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.241102\n",
      "\n",
      "Test set: Average loss: 0.1451, Accuracy: 9549/10000 (95%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.444842\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.542510\n",
      "\n",
      "Test set: Average loss: 0.1514, Accuracy: 9527/10000 (95%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.238440\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.445872\n",
      "\n",
      "Test set: Average loss: 0.1417, Accuracy: 9563/10000 (96%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.355756\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.338480\n",
      "\n",
      "Test set: Average loss: 0.1376, Accuracy: 9566/10000 (96%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.301701\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.346791\n",
      "\n",
      "Test set: Average loss: 0.1294, Accuracy: 9600/10000 (96%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.337550\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.400890\n",
      "\n",
      "Test set: Average loss: 0.1248, Accuracy: 9593/10000 (96%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.322115\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 0.476842\n",
      "\n",
      "Test set: Average loss: 0.1267, Accuracy: 9590/10000 (96%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.364323\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 0.474246\n",
      "\n",
      "Test set: Average loss: 0.1211, Accuracy: 9614/10000 (96%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.256649\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 0.327916\n",
      "\n",
      "Test set: Average loss: 0.1177, Accuracy: 9627/10000 (96%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.276199\n",
      "Train Epoch: 20 [32000/60000 (53%)]\tLoss: 0.278216\n",
      "\n",
      "Test set: Average loss: 0.1130, Accuracy: 9631/10000 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 20 + 1):\n",
    "    train(epoch, train_loader)\n",
    "    test(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test for GTSRB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/39209 (0%)]\tLoss: 3.778571\n",
      "Train Epoch: 1 [32000/39209 (82%)]\tLoss: 3.589249\n",
      "\n",
      "Test set: Average loss: 3.5688, Accuracy: 720/12630 (6%)\n",
      "\n",
      "Train Epoch: 2 [0/39209 (0%)]\tLoss: 3.641155\n",
      "Train Epoch: 2 [32000/39209 (82%)]\tLoss: 3.576416\n",
      "\n",
      "Test set: Average loss: 3.5053, Accuracy: 544/12630 (4%)\n",
      "\n",
      "Train Epoch: 3 [0/39209 (0%)]\tLoss: 3.586509\n",
      "Train Epoch: 3 [32000/39209 (82%)]\tLoss: 3.570819\n",
      "\n",
      "Test set: Average loss: 3.4806, Accuracy: 734/12630 (6%)\n",
      "\n",
      "Train Epoch: 4 [0/39209 (0%)]\tLoss: 3.482228\n",
      "Train Epoch: 4 [32000/39209 (82%)]\tLoss: 3.511797\n",
      "\n",
      "Test set: Average loss: 3.4621, Accuracy: 893/12630 (7%)\n",
      "\n",
      "Train Epoch: 5 [0/39209 (0%)]\tLoss: 3.595092\n",
      "Train Epoch: 5 [32000/39209 (82%)]\tLoss: 3.590954\n",
      "\n",
      "Test set: Average loss: 3.4461, Accuracy: 1142/12630 (9%)\n",
      "\n",
      "Train Epoch: 6 [0/39209 (0%)]\tLoss: 3.557591\n",
      "Train Epoch: 6 [32000/39209 (82%)]\tLoss: 3.406265\n",
      "\n",
      "Test set: Average loss: 3.4193, Accuracy: 1232/12630 (10%)\n",
      "\n",
      "Train Epoch: 7 [0/39209 (0%)]\tLoss: 3.388220\n",
      "Train Epoch: 7 [32000/39209 (82%)]\tLoss: 3.446367\n",
      "\n",
      "Test set: Average loss: 3.3890, Accuracy: 1395/12630 (11%)\n",
      "\n",
      "Train Epoch: 8 [0/39209 (0%)]\tLoss: 3.410860\n",
      "Train Epoch: 8 [32000/39209 (82%)]\tLoss: 3.371262\n",
      "\n",
      "Test set: Average loss: 3.3347, Accuracy: 1839/12630 (15%)\n",
      "\n",
      "Train Epoch: 9 [0/39209 (0%)]\tLoss: 3.509287\n",
      "Train Epoch: 9 [32000/39209 (82%)]\tLoss: 3.347513\n",
      "\n",
      "Test set: Average loss: 3.2099, Accuracy: 2153/12630 (17%)\n",
      "\n",
      "Train Epoch: 10 [0/39209 (0%)]\tLoss: 3.177924\n",
      "Train Epoch: 10 [32000/39209 (82%)]\tLoss: 3.299591\n",
      "\n",
      "Test set: Average loss: 3.0322, Accuracy: 2713/12630 (21%)\n",
      "\n",
      "Train Epoch: 11 [0/39209 (0%)]\tLoss: 2.991155\n",
      "Train Epoch: 11 [32000/39209 (82%)]\tLoss: 3.161827\n",
      "\n",
      "Test set: Average loss: 2.8560, Accuracy: 3037/12630 (24%)\n",
      "\n",
      "Train Epoch: 12 [0/39209 (0%)]\tLoss: 3.267442\n",
      "Train Epoch: 12 [32000/39209 (82%)]\tLoss: 2.936785\n",
      "\n",
      "Test set: Average loss: 2.7307, Accuracy: 3399/12630 (27%)\n",
      "\n",
      "Train Epoch: 13 [0/39209 (0%)]\tLoss: 2.849435\n",
      "Train Epoch: 13 [32000/39209 (82%)]\tLoss: 2.800123\n",
      "\n",
      "Test set: Average loss: 2.5845, Accuracy: 3899/12630 (31%)\n",
      "\n",
      "Train Epoch: 14 [0/39209 (0%)]\tLoss: 2.893932\n",
      "Train Epoch: 14 [32000/39209 (82%)]\tLoss: 2.466466\n",
      "\n",
      "Test set: Average loss: 2.4949, Accuracy: 4166/12630 (33%)\n",
      "\n",
      "Train Epoch: 15 [0/39209 (0%)]\tLoss: 2.830438\n",
      "Train Epoch: 15 [32000/39209 (82%)]\tLoss: 2.640602\n",
      "\n",
      "Test set: Average loss: 2.4023, Accuracy: 4422/12630 (35%)\n",
      "\n",
      "Train Epoch: 16 [0/39209 (0%)]\tLoss: 2.824934\n",
      "Train Epoch: 16 [32000/39209 (82%)]\tLoss: 2.695680\n",
      "\n",
      "Test set: Average loss: 2.3295, Accuracy: 4740/12630 (38%)\n",
      "\n",
      "Train Epoch: 17 [0/39209 (0%)]\tLoss: 2.527122\n",
      "Train Epoch: 17 [32000/39209 (82%)]\tLoss: 2.332079\n",
      "\n",
      "Test set: Average loss: 2.2436, Accuracy: 4885/12630 (39%)\n",
      "\n",
      "Train Epoch: 18 [0/39209 (0%)]\tLoss: 2.509250\n",
      "Train Epoch: 18 [32000/39209 (82%)]\tLoss: 2.495235\n",
      "\n",
      "Test set: Average loss: 2.1864, Accuracy: 5193/12630 (41%)\n",
      "\n",
      "Train Epoch: 19 [0/39209 (0%)]\tLoss: 2.205397\n",
      "Train Epoch: 19 [32000/39209 (82%)]\tLoss: 2.618813\n",
      "\n",
      "Test set: Average loss: 2.1663, Accuracy: 5229/12630 (41%)\n",
      "\n",
      "Train Epoch: 20 [0/39209 (0%)]\tLoss: 2.341220\n",
      "Train Epoch: 20 [32000/39209 (82%)]\tLoss: 2.155421\n",
      "\n",
      "Test set: Average loss: 2.1003, Accuracy: 5492/12630 (43%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 20 + 1):\n",
    "    train(epoch, dset_train)\n",
    "    test(dset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
